# Military Sign Action Recognition App

A real-time sign recognition system that identifies military hand gestures such as **attention**, **pistol**, and **sniper** using Mediapipe Holistic, TensorFlow, and OpenCV. The model is trained on keypoint landmarks and visualized with dynamic probability bars

---

## ğŸ“‹ Features

- ğŸ§  **Pose + Hand + Face Landmark Detection:** Uses Mediapipe Holistic for robust multi-part landmark extraction (33 pose, 468 face, 21 hand landmarks).
- ğŸ” **Trained Gesture Classifier:** Trained a deep LSTM network for classifying signs like attention, pistol, and sniper based on 1662+ keypoints.
- ğŸ–¼ï¸ **Probability Visualization:** Real-time bar chart overlaid on webcam feed to indicate classification confidence.
- ğŸ¥ **Live Gesture Prediction:** Works directly with webcam feed to continuously predict and display gestures frame-by-frame.

---

## Tech Stack

- **Python 3.x** â€“ Core application logic
- **TensorFlow/ Keras** â€“ Framework for model architecture and training and model loading
- **OpenCV** â€“ Webcam input and image handling
- **Mediapipe** â€“ Landmark detection from webcam frames
- **NumPy** â€“ Keypoint formatting and processing

---

## Project Structure

```

â”œâ”€â”€ detector.h5                    # Pre-trained sign recognition model
â”œâ”€â”€ script.py                      # Real-time webcam detection and prediction loop
â”œâ”€â”€ Detection.ipynb                # Data collection, preprocessing, model building and training
â”œâ”€â”€ MP_Data                        # Data collected for training deep LSTM network
|     |â”€â”€ attention
|     |â”€â”€ pistol
|     |â”€â”€ sniper
â”œâ”€â”€ Logs                           # TensorBoard Logs

```
---

## ğŸ§  System Design & Pipeline

### Landmark Extraction

- Uses Mediapipe Holistic to extract
    - Pose landmarks (33 Ã— 4 values)
    - Face mesh landmarks (468 Ã— 3)
    - Left/Right hand landmarks (21 Ã— 3 each)
    - Flattened into a single vector (1662 features) used as model input

### Prediction Logic

- Captures frames via webcam. Extracts landmarks and preprocesses them
- Buffers last 30 frames (for temporal understanding). Passes the sequence to the trained model. 
- Predicts gesture and overlays confidence bars

---

## ğŸ“† Getting Started

### ğŸ“ Prerequisites

- **Python 3.x**  
- **Tensorflow**
- **opencv-python**
- **mediapipe**
- **numpy**

---

###  ğŸš€ Clone and Run

1. **Clone the repository**
```
$ git clone https://github.com/nogi2k2/Sign-Action-Recognition.git
```

2. **Navigate into the project directory**
```
$ cd <directory>
```

3. **Launch the app**  (model .h5 provided in repo)
```
python script.py
```

---
